{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16b8fa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting simpletransformers\n",
      "  Obtaining dependency information for simpletransformers from https://files.pythonhosted.org/packages/e5/85/1c49e063939c70b70e615ee003ef09a8ac82030303a4f1397d0be6590b3d/simpletransformers-0.70.1-py3-none-any.whl.metadata\n",
      "  Downloading simpletransformers-0.70.1-py3-none-any.whl.metadata (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m198.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from simpletransformers) (1.24.3)\n",
      "Requirement already satisfied: requests in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from simpletransformers) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.47.0 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from simpletransformers) (4.65.0)\n",
      "Requirement already satisfied: regex in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from simpletransformers) (2022.7.9)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from simpletransformers) (4.32.1)\n",
      "Requirement already satisfied: datasets in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from simpletransformers) (2.12.0)\n",
      "Requirement already satisfied: scipy in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from simpletransformers) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from simpletransformers) (1.3.0)\n",
      "Collecting seqeval (from simpletransformers)\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m935.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorboard (from simpletransformers)\n",
      "  Obtaining dependency information for tensorboard from https://files.pythonhosted.org/packages/b1/de/021c1d407befb505791764ad2cbd56ceaaa53a746baed01d2e2143f05f18/tensorboard-2.18.0-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tensorboardx (from simpletransformers)\n",
      "  Obtaining dependency information for tensorboardx from https://files.pythonhosted.org/packages/44/71/f3e7c9b2ab67e28c572ab4e9d5fa3499e0d252650f96d8a3a03e26677f53/tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pandas in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from simpletransformers) (2.0.3)\n",
      "Requirement already satisfied: tokenizers in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from simpletransformers) (0.13.2)\n",
      "Collecting wandb>=0.10.32 (from simpletransformers)\n",
      "  Obtaining dependency information for wandb>=0.10.32 from https://files.pythonhosted.org/packages/59/6e/3bf8590ccbce0eb7c705c0f2b1e3700fad891d48524a93e86f52f7000f67/wandb-0.19.0-py3-none-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading wandb-0.19.0-py3-none-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting streamlit (from simpletransformers)\n",
      "  Obtaining dependency information for streamlit from https://files.pythonhosted.org/packages/ae/53/418536f5d0b87bfbe7bbd8c001983c27e9474f82723bd2e529660fd9a534/streamlit-1.40.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading streamlit-1.40.2-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting sentencepiece (from simpletransformers)\n",
      "  Obtaining dependency information for sentencepiece from https://files.pythonhosted.org/packages/de/42/ae30952c4a0bd773e90c9bf2579f5533037c886dfc8ec68133d5694f4dd2/sentencepiece-0.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: filelock in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from transformers>=4.31.0->simpletransformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from transformers>=4.31.0->simpletransformers) (0.15.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from transformers>=4.31.0->simpletransformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from transformers>=4.31.0->simpletransformers) (6.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from transformers>=4.31.0->simpletransformers) (0.3.2)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from wandb>=0.10.32->simpletransformers) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb>=0.10.32->simpletransformers)\n",
      "  Obtaining dependency information for docker-pycreds>=0.4.0 from https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from wandb>=0.10.32->simpletransformers) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from wandb>=0.10.32->simpletransformers) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from wandb>=0.10.32->simpletransformers) (5.29.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from wandb>=0.10.32->simpletransformers) (5.9.0)\n",
      "Collecting pydantic<3,>=2.6 (from wandb>=0.10.32->simpletransformers)\n",
      "  Obtaining dependency information for pydantic<3,>=2.6 from https://files.pythonhosted.org/packages/62/51/72c18c55cf2f46ff4f91ebcc8f75aa30f7305f3d726be3f4ebffb4ae972b/pydantic-2.10.3-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.10.3-py3-none-any.whl.metadata (172 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m790.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentry-sdk>=2.0.0 (from wandb>=0.10.32->simpletransformers)\n",
      "  Obtaining dependency information for sentry-sdk>=2.0.0 from https://files.pythonhosted.org/packages/c6/6b/191ca63f05d3ecc7600b5b3abd493a4c1b8468289c9737a7735ade1fedca/sentry_sdk-2.19.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading sentry_sdk-2.19.0-py2.py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting setproctitle (from wandb>=0.10.32->simpletransformers)\n",
      "  Obtaining dependency information for setproctitle from https://files.pythonhosted.org/packages/46/54/e3aa4f46eddf795f10452ea878ff85c3496d36409636530f9a37e2de3cbe/setproctitle-1.3.4-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading setproctitle-1.3.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from wandb>=0.10.32->simpletransformers) (68.0.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from wandb>=0.10.32->simpletransformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from requests->simpletransformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from requests->simpletransformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from requests->simpletransformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from requests->simpletransformers) (2023.7.22)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from datasets->simpletransformers) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from datasets->simpletransformers) (0.3.6)\n",
      "Requirement already satisfied: xxhash in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from datasets->simpletransformers) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from datasets->simpletransformers) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from datasets->simpletransformers) (2024.10.0)\n",
      "Requirement already satisfied: aiohttp in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from datasets->simpletransformers) (3.8.5)\n",
      "Requirement already satisfied: responses<0.19 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from datasets->simpletransformers) (0.13.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from pandas->simpletransformers) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from pandas->simpletransformers) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from pandas->simpletransformers) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from scikit-learn->simpletransformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from scikit-learn->simpletransformers) (2.2.0)\n",
      "Collecting altair<6,>=4.0 (from streamlit->simpletransformers)\n",
      "  Obtaining dependency information for altair<6,>=4.0 from https://files.pythonhosted.org/packages/aa/f3/0b6ced594e51cc95d8c1fc1640d3623770d01e4969d29c0bd09945fafefa/altair-5.5.0-py3-none-any.whl.metadata\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit->simpletransformers)\n",
      "  Obtaining dependency information for blinker<2,>=1.0.0 from https://files.pythonhosted.org/packages/10/cb/f2ad4230dc2eb1a74edf38f1a38b9b52277f75bef262d8908e60d957e13c/blinker-1.9.0-py3-none-any.whl.metadata\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from streamlit->simpletransformers) (5.5.0)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from streamlit->simpletransformers) (9.4.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from streamlit->simpletransformers) (13.9.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from streamlit->simpletransformers) (8.2.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from streamlit->simpletransformers) (0.10.2)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit->simpletransformers)\n",
      "  Obtaining dependency information for pydeck<1,>=0.8.0b4 from https://files.pythonhosted.org/packages/ab/4c/b888e6cf58bd9db9c93f40d1c6be8283ff49d88919231afe93a6bcf61626/pydeck-0.9.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from streamlit->simpletransformers) (6.3.2)\n",
      "Collecting absl-py>=0.4 (from tensorboard->simpletransformers)\n",
      "  Obtaining dependency information for absl-py>=0.4 from https://files.pythonhosted.org/packages/a2/ad/e0d3c824784ff121c03cc031f944bc7e139a8f1870ffd2845cc2dd76f6c4/absl_py-2.1.0-py3-none-any.whl.metadata\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard->simpletransformers)\n",
      "  Obtaining dependency information for grpcio>=1.48.2 from https://files.pythonhosted.org/packages/07/fd/e5fa75b5ddf5d9f16606196973f9c2b4b1adf5a1735117eb7129fc33d2ec/grpcio-1.68.1-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading grpcio-1.68.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from tensorboard->simpletransformers) (3.4.1)\n",
      "Requirement already satisfied: six>1.9 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from tensorboard->simpletransformers) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->simpletransformers)\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/7a/13/e503968fefabd4c6b2650af21e110aa8466fe21432cd7c43a84577a89438/tensorboard_data_server-0.7.2-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from tensorboard->simpletransformers) (2.2.3)\n",
      "Requirement already satisfied: jinja2 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (4.17.3)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit->simpletransformers)\n",
      "  Obtaining dependency information for narwhals>=1.14.2 from https://files.pythonhosted.org/packages/ac/e7/fe3d69098e628e81cf317e860474e5df02a5a681b031acbf2aaf192cef3f/narwhals-1.15.2-py3-none-any.whl.metadata\n",
      "  Downloading narwhals-1.15.2-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets->simpletransformers) (24.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets->simpletransformers) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets->simpletransformers) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets->simpletransformers) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets->simpletransformers) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets->simpletransformers) (1.2.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (4.0.11)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=2.6->wandb>=0.10.32->simpletransformers)\n",
      "  Obtaining dependency information for annotated-types>=0.6.0 from https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl.metadata\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic<3,>=2.6->wandb>=0.10.32->simpletransformers)\n",
      "  Obtaining dependency information for pydantic-core==2.27.1 from https://files.pythonhosted.org/packages/1c/00/0804e84a78b7fdb394fff4c4f429815a10e5e0993e6ae0e0b27dd20379ee/pydantic_core-2.27.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading pydantic_core-2.27.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (2.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard->simpletransformers) (2.1.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (5.0.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/mdmehran/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->simpletransformers) (0.1.0)\n",
      "Downloading simpletransformers-0.70.1-py3-none-any.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.3/316.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wandb-0.19.0-py3-none-macosx_11_0_arm64.whl (19.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp311-cp311-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading streamlit-1.40.2-py2.py3-none-any.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.2/731.2 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading grpcio-1.68.1-cp311-cp311-macosx_10_9_universal2.whl (11.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.10.3-py3-none-any.whl (456 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.0/457.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.27.1-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading sentry_sdk-2.19.0-py2.py3-none-any.whl (322 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading setproctitle-1.3.4-cp311-cp311-macosx_11_0_arm64.whl (11 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading narwhals-1.15.2-py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.8/233.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16164 sha256=508c7b5006f969647056efbbee5e5a7773b641eb03863cb4e71e42d16445cf1d\n",
      "  Stored in directory: /Users/mdmehran/Library/Caches/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
      "Successfully built seqeval\n",
      "Installing collected packages: sentencepiece, tensorboardx, tensorboard-data-server, setproctitle, sentry-sdk, pydantic-core, narwhals, grpcio, docker-pycreds, blinker, annotated-types, absl-py, tensorboard, pydeck, pydantic, altair, wandb, streamlit, seqeval, simpletransformers\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.8\n",
      "    Uninstalling pydantic-1.10.8:\n",
      "      Successfully uninstalled pydantic-1.10.8\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anaconda-cloud-auth 0.1.3 requires pydantic<2.0, but you have pydantic 2.10.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-2.1.0 altair-5.5.0 annotated-types-0.7.0 blinker-1.9.0 docker-pycreds-0.4.0 grpcio-1.68.1 narwhals-1.15.2 pydantic-2.10.3 pydantic-core-2.27.1 pydeck-0.9.1 sentencepiece-0.2.0 sentry-sdk-2.19.0 seqeval-1.2.2 setproctitle-1.3.4 simpletransformers-0.70.1 streamlit-1.40.2 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorboardx-2.6.2.2 wandb-0.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install simpletransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2273435d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mdmehran/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# #from google.colab import files\n",
    "# from tqdm import tqdm\n",
    "# import warnings\n",
    "# warnings.simplefilter('ignore')\n",
    "# import gc\n",
    "from scipy.special import softmax\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "# import sklearn\n",
    "from sklearn.metrics import log_loss\n",
    "# from sklearn.metrics import *\n",
    "# from sklearn.model_selection import *\n",
    "# import re\n",
    "# import random\n",
    "# import torch\n",
    "# pd.options.display.max_colwidth = 200\n",
    "\n",
    "# def seed_all(seed_value):\n",
    "#     random.seed(seed_value) # Python\n",
    "#     np.random.seed(seed_value) # cpu vars\n",
    "#     torch.manual_seed(seed_value) # cpu  vars\n",
    "    \n",
    "#     if torch.cuda.is_available(): \n",
    "#         torch.cuda.manual_seed(seed_value)\n",
    "#         torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "#         torch.backends.cudnn.deterministic = True  #needed\n",
    "#         torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "387876fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/Train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/Train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/Test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/Train.csv'"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/Train.csv')\n",
    "test = pd.read_csv('data/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f937626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the base directory (project root or wherever your data folder is)\n",
    "base_dir = \"../data\"  # You can adjust this if needed\n",
    "\n",
    "# Define a function to load CSV files\n",
    "def load_data(file_name):\n",
    "    return pd.read_csv(os.path.join(base_dir, file_name))\n",
    "\n",
    "# Load the datasets using the function\n",
    "train = load_data(\"Train.csv\")\n",
    "test = load_data(\"Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0e1487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e29a0ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_2</td>\n",
       "      <td>Why is  explained in the video take a look</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_3</td>\n",
       "      <td>Ed Davey fasting for Ramadan No contest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4</td>\n",
       "      <td>Is Doja Cat good or do you just miss Nicki Minaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_8</td>\n",
       "      <td>How Boris Johnson s cheery wounded in action p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_9</td>\n",
       "      <td>Man it s terrible Not even a reason to get on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                               text\n",
       "0  test_2         Why is  explained in the video take a look\n",
       "1  test_3            Ed Davey fasting for Ramadan No contest\n",
       "2  test_4   Is Doja Cat good or do you just miss Nicki Minaj\n",
       "3  test_8  How Boris Johnson s cheery wounded in action p...\n",
       "4  test_9  Man it s terrible Not even a reason to get on ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe6cd4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    2746\n",
       "1    2541\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c8d3b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train=train.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "530f391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1=train.drop(['ID'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c037ee69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>The bitcoin halving is cancelled due to</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>MercyOfAllah In good times wrapped in its gran...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>266 Days No Digital India No Murder of e learn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>India is likely to run out of the remaining RN...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>In these tough times the best way to grow is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               text  target\n",
       "0  train_0            The bitcoin halving is cancelled due to       1\n",
       "1  train_1  MercyOfAllah In good times wrapped in its gran...       0\n",
       "2  train_2  266 Days No Digital India No Murder of e learn...       1\n",
       "3  train_3  India is likely to run out of the remaining RN...       1\n",
       "4  train_4  In these tough times the best way to grow is t...       0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1bf9ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_2</td>\n",
       "      <td>Why is  explained in the video take a look</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_3</td>\n",
       "      <td>Ed Davey fasting for Ramadan No contest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4</td>\n",
       "      <td>Is Doja Cat good or do you just miss Nicki Minaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_8</td>\n",
       "      <td>How Boris Johnson s cheery wounded in action p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_9</td>\n",
       "      <td>Man it s terrible Not even a reason to get on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                               text\n",
       "0  test_2         Why is  explained in the video take a look\n",
       "1  test_3            Ed Davey fasting for Ramadan No contest\n",
       "2  test_4   Is Doja Cat good or do you just miss Nicki Minaj\n",
       "3  test_8  How Boris Johnson s cheery wounded in action p...\n",
       "4  test_9  Man it s terrible Not even a reason to get on ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8081b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1=test.drop(['ID'],axis=1)\n",
    "test1['label']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56765a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/simpletransformers/classification/classification_model.py:610: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/simpletransformers/classification/classification_model.py:1453: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log_Loss: 0.2378435464140295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/simpletransformers/classification/classification_model.py:1453: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1146: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:993: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/simpletransformers/classification/classification_model.py:610: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/simpletransformers/classification/classification_model.py:1453: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log_Loss: 0.25971115031385744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/simpletransformers/classification/classification_model.py:1453: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1146: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:993: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/simpletransformers/classification/classification_model.py:610: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/simpletransformers/classification/classification_model.py:1453: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log_Loss: 0.20201703326395737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/simpletransformers/classification/classification_model.py:1453: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "err=[]\n",
    "y_pred_tot=[]\n",
    "\n",
    "fold=StratifiedKFold(n_splits=20, shuffle=True, random_state=2)\n",
    "i=1\n",
    "for train_index, test_index in fold.split(train1,train1['target']):\n",
    "    train1_trn, train1_val = train1.iloc[train_index], train1.iloc[test_index]\n",
    "    model = ClassificationModel('roberta', 'roberta-large', use_cuda=True,num_labels=2, args={'train_batch_size':32,\n",
    "                                                                         'reprocess_input_data': True,\n",
    "                                                                         'overwrite_output_dir': True,\n",
    "                                                                         'fp16': False,\n",
    "                                                                         'do_lower_case': False,\n",
    "                                                                         'num_train_epochs': 1,\n",
    "                                                                         'max_seq_length': 64,\n",
    "                                                                         'regression': False,\n",
    "                                                                         'manual_seed': 2,\n",
    "                                                                         \"learning_rate\":1e-5,\n",
    "                                                                         'weight_decay':0,\n",
    "                                                                         \"save_eval_checkpoints\": False,\n",
    "                                                                         \"save_model_every_epoch\": False,\n",
    "                                                                         \"silent\": True})\n",
    "    model.train_model(train1_trn)\n",
    "    raw_outputs_val = model.eval_model(train1_val)[1]\n",
    "    raw_outputs_val = softmax(raw_outputs_val,axis=1)[:,1]\n",
    "    print(f\"Log_Loss: {log_loss(train1_val['target'], raw_outputs_val)}\")\n",
    "    err.append(log_loss(train1_val['target'], raw_outputs_val))\n",
    "    raw_outputs_test = model.eval_model(test1)[1]\n",
    "    raw_outputs_test = softmax(raw_outputs_test,axis=1)[:,1]\n",
    "    y_pred_tot.append(raw_outputs_test)\n",
    "print(\"Mean LogLoss: \",np.mean(err))\n",
    "final=pd.DataFrame()\n",
    "final['ID']=test['ID']\n",
    "final['target']=np.mean(y_pred_tot, 0)\n",
    "print(final.shape)\n",
    "final.to_csv('roberta_1e5.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c71fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "err=[]\n",
    "y_pred_tot=[]\n",
    "\n",
    "fold=StratifiedKFold(n_splits=20, shuffle=True, random_state=2)\n",
    "i=1\n",
    "for train_index, test_index in fold.split(train1,train1['target']):\n",
    "    train1_trn, train1_val = train1.iloc[train_index], train1.iloc[test_index]\n",
    "    model = ClassificationModel('bert', 'bert-large-uncased-whole-word-masking', use_cuda=True,num_labels=2, args={'train_batch_size':32,\n",
    "                                                                         'reprocess_input_data': True,\n",
    "                                                                         'overwrite_output_dir': True,\n",
    "                                                                         'fp16': False,\n",
    "                                                                         'do_lower_case': True,\n",
    "                                                                         'num_train_epochs': 2,\n",
    "                                                                         'max_seq_length': 64,\n",
    "                                                                         'regression': False,\n",
    "                                                                         'manual_seed': 2,\n",
    "                                                                         \"learning_rate\":1e-5,\n",
    "                                                                         'weight_decay':0,\n",
    "                                                                         \"save_eval_checkpoints\": False,\n",
    "                                                                         \"save_model_every_epoch\": False,\n",
    "                                                                         \"silent\": True})\n",
    "    model.train_model(train1_trn)\n",
    "    raw_outputs_val = model.eval_model(train1_val)[1]\n",
    "    raw_outputs_val = softmax(raw_outputs_val,axis=1)[:,1]\n",
    "    print(f\"Log_Loss: {log_loss(train1_val['target'], raw_outputs_val)}\")\n",
    "    err.append(log_loss(train1_val['target'], raw_outputs_val))\n",
    "    raw_outputs_test = model.eval_model(test1)[1]\n",
    "    raw_outputs_test = softmax(raw_outputs_test,axis=1)[:,1]\n",
    "    y_pred_tot.append(raw_outputs_test)\n",
    "print(\"Mean LogLoss: \",np.mean(err))\n",
    "final=pd.DataFrame()\n",
    "final['ID']=test['ID']\n",
    "final['target']=np.mean(y_pred_tot, 0)\n",
    "print(final.shape)\n",
    "final.to_csv('bert_1e5.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85667b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
